{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logos cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWHD/4gboldfhV8HVk/Pjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadahmed388/projects/blob/main/logos_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AymjmdNjbBKI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "CHANNELS = 3\n",
        "EPOCHS =50\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   \"/content/drive/MyDrive/Car_Brand_Logos/Train\",\n",
        "   shuffle=True,\n",
        "   image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "   batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Car_Brand_Logos/Test\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ") \n",
        "\n",
        "#test_ds = test.take(round(len(test)*0.5))\n",
        "#val_ds = test.skip(len(test_ds))\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUtVDw8JOXuH",
        "outputId": "a44867dc-5824-413d-d95d-deb878b3353a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2456 files belonging to 8 classes.\n",
            "Found 391 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9WXtAnWgN1D",
        "outputId": "5d0f4a5d-b089-4581-f7c0-ce6e9562efd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "def check_images( s_dir, ext_list):\n",
        "    bad_images=[]\n",
        "    bad_ext=[]\n",
        "    s_list= os.listdir(s_dir)\n",
        "    for klass in s_list:\n",
        "        klass_path=os.path.join (s_dir, klass)\n",
        "        print ('processing class directory ', klass)\n",
        "        if os.path.isdir(klass_path):\n",
        "            file_list=os.listdir(klass_path)\n",
        "            for f in file_list:               \n",
        "                f_path=os.path.join (klass_path,f)\n",
        "                tip = imghdr.what(f_path)\n",
        "                if ext_list.count(tip) == 0:\n",
        "                  bad_images.append(f_path)\n",
        "                if os.path.isfile(f_path):\n",
        "                    try:\n",
        "                        img=cv2.imread(f_path)\n",
        "                        shape=img.shape\n",
        "                    except:\n",
        "                        print('file ', f_path, ' is not a valid image file')\n",
        "                        bad_images.append(f_path)\n",
        "                else:\n",
        "                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
        "        else:\n",
        "            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
        "    return bad_images, bad_ext\n",
        "\n",
        "source_dir =r'/content/drive/MyDrive/Car_Brand_Logos/Test'\n",
        "good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
        "bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
        "if len(bad_file_list) !=0:\n",
        "    print('improper image files are listed below')\n",
        "    for i in range (len(bad_file_list)):\n",
        "        print (bad_file_list[i])\n",
        "else:\n",
        "    print(' no improper image files were found')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_GfcHbeckCx",
        "outputId": "7fee9f80-5286-4f39-cf0c-3d1846bb8af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing class directory  toyota\n",
            "processing class directory  volkswagen\n",
            "processing class directory  hyundai\n",
            "processing class directory  mercedes\n",
            "processing class directory  skoda\n",
            "processing class directory  lexus\n",
            "processing class directory  mazda\n",
            "processing class directory  opel\n",
            " no improper image files were found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in bad_file_list:\n",
        "  os.remove(i)"
      ],
      "metadata": {
        "id": "vBZEI7gdpfPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FOUdM4Jpphsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "\n",
        "train_ds = dataset.take(round(len(dataset)*train_size))\n",
        "test_ds = dataset.skip(len(train_ds))\n",
        "\n",
        "val_ds = test_ds.take(round(len(test_ds)*0.5))\n",
        "test_ds = test_ds.skip(len(val_ds))\n",
        "\n",
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    \n",
        "    ds_size = len(ds)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size , seed = 12)\n",
        "        \n",
        "    train_size = int(train_split *ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "zyymdhAtLwan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "    ])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    \n",
        "])\n",
        "\n",
        "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "n_classes = 8\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation ='relu'),\n",
        "    layers.Dense(n_classes, activation ='softmax'),\n",
        "])\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "SMtTqZgALxjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCH2AQ_aMIiH",
        "outputId": "2a5a53bb-7b88-4523-e582-98276345fe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_12 (Sequential)  (32, 256, 256, 3)         0         \n",
            "                                                                 \n",
            " sequential_13 (Sequential)  (32, 256, 256, 3)         0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (32, 254, 254, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (32, 127, 127, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (32, 125, 125, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (32, 62, 62, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (32, 60, 60, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (32, 30, 30, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (32, 28, 28, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (32, 14, 14, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (32, 12, 12, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (32, 6, 6, 64)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (32, 4, 4, 64)            36928     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (32, 2, 2, 64)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (32, 256)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (32, 64)                  16448     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (32, 8)                   520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,072\n",
            "Trainable params: 184,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IDkYL9bMMQTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=50,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose = 1,\n",
        "    validation_data = test_ds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjzKLt5pMUSu",
        "outputId": "3535c2f7-33d4-4a9b-e0c5-3303d64b59cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2894 - accuracy: 0.9059 - val_loss: 1.6393 - val_accuracy: 0.6854\n",
            "Epoch 42/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2981 - accuracy: 0.8998 - val_loss: 1.7022 - val_accuracy: 0.6726\n",
            "Epoch 43/50\n",
            "77/77 [==============================] - 5s 71ms/step - loss: 0.2974 - accuracy: 0.8982 - val_loss: 1.8007 - val_accuracy: 0.6496\n",
            "Epoch 44/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2703 - accuracy: 0.9055 - val_loss: 1.7859 - val_accuracy: 0.6803\n",
            "Epoch 45/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2893 - accuracy: 0.9039 - val_loss: 1.9134 - val_accuracy: 0.6496\n",
            "Epoch 46/50\n",
            "77/77 [==============================] - 6s 74ms/step - loss: 0.3387 - accuracy: 0.8888 - val_loss: 1.6973 - val_accuracy: 0.6880\n",
            "Epoch 47/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2966 - accuracy: 0.9039 - val_loss: 1.5657 - val_accuracy: 0.6777\n",
            "Epoch 48/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2735 - accuracy: 0.9023 - val_loss: 1.7972 - val_accuracy: 0.6675\n",
            "Epoch 49/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.2734 - accuracy: 0.9072 - val_loss: 1.8637 - val_accuracy: 0.6752\n",
            "Epoch 50/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.3036 - accuracy: 0.8994 - val_loss: 1.7573 - val_accuracy: 0.6957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/logo_scanning_model/model_1')"
      ],
      "metadata": {
        "id": "qbc8lQ4rMezE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289208ff-266b-4405-eb93-a6e2ec2f2cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/logo_scanning_model/model_1/assets\n"
          ]
        }
      ]
    }
  ]
}